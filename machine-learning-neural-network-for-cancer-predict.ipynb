{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6913870,"sourceType":"datasetVersion","datasetId":3970537}],"dockerImageVersionId":30558,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# Data handling\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#Data Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n#Pre-processing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\n#classification\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-07T21:03:03.112698Z","iopub.execute_input":"2023-11-07T21:03:03.113071Z","iopub.status.idle":"2023-11-07T21:03:03.119727Z","shell.execute_reply.started":"2023-11-07T21:03:03.113044Z","shell.execute_reply":"2023-11-07T21:03:03.118695Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Read the Data","metadata":{}},{"cell_type":"code","source":"#read data directly from a github repository\nfile_url='/kaggle/input/cancer-gene-expression-data/cancer_gene_expression.csv'\n\ndataframe=pd.read_csv(file_url)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:03.121760Z","iopub.execute_input":"2023-11-07T21:03:03.122551Z","iopub.status.idle":"2023-11-07T21:03:04.673469Z","shell.execute_reply.started":"2023-11-07T21:03:03.122516Z","shell.execute_reply":"2023-11-07T21:03:04.672143Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Data Exploration & Cleaning","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#let's check the number of samples and features\n#note:the last column contain the labels. it is not considered as a feature\n\nprint(dataframe.shape)\n#let's check some of the columns (first, second and third columns)\nprint(dataframe.columns[0:3])\n#lets check the name of the last column of this dataframe\n\ndataframe.columns[-1]\n#check for missing values\ndatanul=dataframe.isnull().sum()\ng=[i for i in datanul if i>0]\n\nprint('columns with missing values:%d'%len(g))","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:04.675638Z","iopub.execute_input":"2023-11-07T21:03:04.675975Z","iopub.status.idle":"2023-11-07T21:03:04.696924Z","shell.execute_reply.started":"2023-11-07T21:03:04.675944Z","shell.execute_reply":"2023-11-07T21:03:04.695213Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#let's check how many different cancer types are there in the data\n#note: in this tutorial the cancer types will be referred to as classes or labels\n\nprint(dataframe['Cancer_Type'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:04.698757Z","iopub.execute_input":"2023-11-07T21:03:04.699173Z","iopub.status.idle":"2023-11-07T21:03:04.707628Z","shell.execute_reply.started":"2023-11-07T21:03:04.699138Z","shell.execute_reply":"2023-11-07T21:03:04.706326Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can see that there are 5 classes/cancer types. And you can also see the number of samples diagnosed with a cancer type\n\nData preprocesing\n\nThis is done to put the data in an appropriate format before modelling","metadata":{}},{"cell_type":"code","source":"#we will now seperate the feature values from the class. we do this because scikit-learn requires that features and class are separated before parsing them to the classifiers.\nX=dataframe.iloc[:,0:-1]\ny=dataframe.iloc[:,-1]","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:04.709953Z","iopub.execute_input":"2023-11-07T21:03:04.710280Z","iopub.status.idle":"2023-11-07T21:03:04.735145Z","shell.execute_reply.started":"2023-11-07T21:03:04.710249Z","shell.execute_reply":"2023-11-07T21:03:04.733517Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Encode labels\n\nThe labels for this data are categorical and we therefore have to convert them to numeric forms. This is referred to as encoding. Machine learning models usually require input data to be in numeric forms, hence we encoding the labels.","metadata":{}},{"cell_type":"code","source":"#let's encode target labels (y) with values between 0 and n_classes-1.\n#encoding will be done using the LabelEncoder\nlabel_encoder=LabelEncoder()\nlabel_encoder.fit(y)\ny=label_encoder.transform(y)\nlabels=label_encoder.classes_\nclasses=np.unique(y)\nnclasses=np.unique(y).shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:04.736484Z","iopub.execute_input":"2023-11-07T21:03:04.736889Z","iopub.status.idle":"2023-11-07T21:03:04.754834Z","shell.execute_reply.started":"2023-11-07T21:03:04.736853Z","shell.execute_reply":"2023-11-07T21:03:04.753510Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Data Splitting\nData is split into three: training, validation and test sets\n-training set is used for training\n-validation set is used for evaluating the model during training.\n-test set is used to test the model after training and tuning has been completed.","metadata":{}},{"cell_type":"code","source":"#split data into training,validation and test sets\n\n#split the data into training and test sets\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n\n#split the training set into two (training and validation)\nX_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:04.756759Z","iopub.execute_input":"2023-11-07T21:03:04.757114Z","iopub.status.idle":"2023-11-07T21:03:04.818154Z","shell.execute_reply.started":"2023-11-07T21:03:04.757083Z","shell.execute_reply":"2023-11-07T21:03:04.817449Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Data Normalization\nData normalization is done so that the values are in the same range. This will improve model performance and avoid bias.\nNormalization is performed separately on each data set. This is done to prevent data leakage.","metadata":{}},{"cell_type":"code","source":"### scale the data between 0-1\nmin_max_scaler=MinMaxScaler()\nX_train=min_max_scaler.fit_transform(X_train)\nX_val=min_max_scaler.fit_transform(X_val)\nX_test=min_max_scaler.fit_transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:04.819175Z","iopub.execute_input":"2023-11-07T21:03:04.820269Z","iopub.status.idle":"2023-11-07T21:03:05.208375Z","shell.execute_reply.started":"2023-11-07T21:03:04.820235Z","shell.execute_reply":"2023-11-07T21:03:05.206534Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Build the Neural Network Model","metadata":{}},{"cell_type":"code","source":"#define model\nmodel = Sequential()\n\n#hidden layer 1\nmodel.add(Dense(40, input_dim=X_train.shape[1], activation='relu'))\n\n#hidden layer 2\nmodel.add(Dense(20, activation='relu'))\n\n#output layer\nmodel.add(Dense(nclasses, activation='softmax'))\n\n#define optimizer and learning rate. We will use Adam optimizer\nopt_adam = keras.optimizers.Adam(learning_rate=0.001)\n\nmodel.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=opt_adam, metrics=[keras.metrics.SparseCategoricalAccuracy()])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:05.209988Z","iopub.execute_input":"2023-11-07T21:03:05.210690Z","iopub.status.idle":"2023-11-07T21:03:05.425610Z","shell.execute_reply.started":"2023-11-07T21:03:05.210664Z","shell.execute_reply":"2023-11-07T21:03:05.424038Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#fit the model to the training data\nhistory = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32,epochs=200, verbose=1)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:05.426950Z","iopub.execute_input":"2023-11-07T21:03:05.427331Z","iopub.status.idle":"2023-11-07T21:03:27.001142Z","shell.execute_reply.started":"2023-11-07T21:03:05.427299Z","shell.execute_reply":"2023-11-07T21:03:26.999990Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = model.predict(X_test)\n_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:27.003788Z","iopub.execute_input":"2023-11-07T21:03:27.004973Z","iopub.status.idle":"2023-11-07T21:03:27.361801Z","shell.execute_reply.started":"2023-11-07T21:03:27.004942Z","shell.execute_reply":"2023-11-07T21:03:27.360908Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#get the predictions for the first 20 samples in the test set\nfor index,entry in enumerate(predictions[0:20,:]):\n    print('predicted:%d ,actual:%d'%(np.argmax(entry),y_test[index]))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:27.362964Z","iopub.execute_input":"2023-11-07T21:03:27.363849Z","iopub.status.idle":"2023-11-07T21:03:27.369792Z","shell.execute_reply.started":"2023-11-07T21:03:27.363817Z","shell.execute_reply":"2023-11-07T21:03:27.368588Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# summarize history for accuracy\nplt.plot(history.history['sparse_categorical_accuracy'])\nplt.plot(history.history['val_sparse_categorical_accuracy'])\nplt.title('model performance')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='lower right')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:27.371473Z","iopub.execute_input":"2023-11-07T21:03:27.371837Z","iopub.status.idle":"2023-11-07T21:03:27.654838Z","shell.execute_reply.started":"2023-11-07T21:03:27.371807Z","shell.execute_reply":"2023-11-07T21:03:27.653708Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='lower right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-07T21:03:27.656315Z","iopub.execute_input":"2023-11-07T21:03:27.656626Z","iopub.status.idle":"2023-11-07T21:03:27.884788Z","shell.execute_reply.started":"2023-11-07T21:03:27.656602Z","shell.execute_reply":"2023-11-07T21:03:27.883253Z"},"trusted":true},"outputs":[],"execution_count":null}]}